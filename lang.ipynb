{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INGESTING PDFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the PDFs into the program\n",
    "\n",
    "PATH = r'C:\\Users\\Kola PC\\Desktop\\RAGging\\sourcepdfs\\Lawal, Kolawole Oluranti_C.V.pdf'\n",
    "\n",
    "if PATH:\n",
    "    loader = PyPDFLoader(PATH)\n",
    "    data = loader.load()\n",
    "else:\n",
    "    print('There is no file!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Kolawole Lawal\\nI develop, implement, deploy and maintain cost-effective software solutions to enterprise-\\nscale problems.\\nIbadan\\nlawalkolawole902@gmail.com\\n+234 707 571 2794\\nA highly motivated individual willing and capable of seamlessly honing and integrating relevant set of\\ntechnical and soft skills to leverage and exploit opportunities in dynamic situations in order to achieve\\norganisational business and operational goals.\\nWilling to relocate: Anywhere\\nPersonal Details\\nCurrently Employed: No\\nDate of Birth: 2000-01-11\\nHighest Level of Education: Master's\\nIndustry: Administrative Assistance, Analytics, Business Operations, Customer Service, Hospitality\\n& Tourism, IT Operations & Helpdesk, Information Design & Documentation, Information Technology,\\nManagement, Project Management, Quality Assurance, Software Development\\nNYSC Status: Completed\\nWork Experience\\nNIGHT SUPERVISOR AND AUDITOR\\nBRAVA HOTEL-Ibadan\\nSeptember 2024 to Present\\n1. I developed and maintained standards to maximize guest satisfaction.\\n2. I reviewed and ensured compliance with company standards among staff of the night shift.\\n3. I reviewed sales report from the hotel's point of sales departments (laundry, rooms, food and\\nbeverage).\\n4. I collated sales report from the hotel's point of sales departments (as listed above)\\n5. I developed a spreadsheet (and used spreadsheet formulas for automated calculations) that will\\nbe maintained subsequently by trained personnel to render a summary report on daily revenue for\\nmanagement consumption.\\n6. I developed a database for the hotel's front desk consumption to manage inhouse guests and their\\ntransaction within the hotel.\\n7. I developed a web application using Streamlit (a Python module) that receives input from the front\\ndesk officer/hotel receptionist on the front end and connects at the back end to the hotel's database for\\nstoring guests' information and transaction.\\n8. I automated the steps of loading of the web app using BASH shell script so that instead of the complex\\nsteps required to load the web app, the user just clicks a button on the desktop screen.\\n9. I trained the staff on using the web application I created.\\n10. I hosted my web application on GitHub to capture version changes and future maintenance in Git\\ncommits.\\n11. I maintained and added functionalities via very descriptive git commits from VSCode on my local\\ndevice.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].page_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VECTOR EMBEDDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is to convert the ingested human readable document to computer readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?25lpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠹ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠸ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠼ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠴ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠦ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠧ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠇ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠏ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠋ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest ⠙ \u001b[?25h\u001b[?25l\u001b[2K\u001b[1Gpulling manifest \n",
      "pulling 970aa74c0a90... 100% ▕████████████████▏ 274 MB                         \n",
      "pulling c71d239df917... 100% ▕████████████████▏  11 KB                         \n",
      "pulling ce4a164fc046... 100% ▕████████████████▏   17 B                         \n",
      "pulling 31df23ea7daa... 100% ▕████████████████▏  420 B                         \n",
      "verifying sha256 digest \n",
      "writing manifest \n",
      "success \u001b[?25h\n"
     ]
    }
   ],
   "source": [
    "!ollama pull nomic-embed-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                       ID              SIZE      MODIFIED       \n",
      "nomic-embed-text:latest    0a109f422b47    274 MB    10 seconds ago    \n",
      "llama3.2:latest            a80c4f17acd5    2.0 GB    12 days ago       \n"
     ]
    }
   ],
   "source": [
    "!ollama list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split and chunk the text\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 200,\n",
    "    chunk_overlap = 20\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kola PC\\AppData\\Local\\Temp\\ipykernel_13052\\1761105009.py:4: LangChainDeprecationWarning: The class `OllamaEmbeddings` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import OllamaEmbeddings``.\n",
      "  embedding=OllamaEmbeddings(model = 'nomic-embed-text', show_progress=True),\n",
      "OllamaEmbeddings: 100%|██████████| 57/57 [08:04<00:00,  8.49s/it]\n"
     ]
    }
   ],
   "source": [
    "# add the chunks into a vector database\n",
    "vector_db = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=OllamaEmbeddings(model = 'nomic-embed-text', show_progress=True),\n",
    "    collection_name = 'local-rag'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INFORMATION RETRIEVAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_community.chat_models import ChatOllama\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kola PC\\AppData\\Local\\Temp\\ipykernel_13052\\3729856374.py:5: LangChainDeprecationWarning: The class `ChatOllama` was deprecated in LangChain 0.3.1 and will be removed in 1.0.0. An updated version of the class exists in the :class:`~langchain-ollama package and should be used instead. To use it run `pip install -U :class:`~langchain-ollama` and import as `from :class:`~langchain_ollama import ChatOllama``.\n",
      "  LLM = ChatOllama(model = local_model)\n"
     ]
    }
   ],
   "source": [
    "# LLM from Ollama. Note that this LLM has to be intsalled in your local device already before you can use them.\n",
    "# You may use the command <ollama pull the_LLM-model> to download and install an Ollama Model.\n",
    "\n",
    "local_model = 'llama3.2'\n",
    "LLM = ChatOllama(model = local_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT = PromptTemplate(\n",
    "    input_variables=[\"question\"],\n",
    "    template = \"\"\"You are an AI language model assistant. Your task is to generate five different\n",
    "    versions of the given user question to retrieve relevant documents from a vector database. By\n",
    "    generating multiple perspective on the user question, your goal is to help the user overcome\n",
    "    some of the limitations of the distance-based similarity search. Provide these alternative\n",
    "    questions seperated by newlines.\n",
    "    Original Question: {question}\"\"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = MultiQueryRetriever.from_llm(\n",
    "    vector_db.as_retriever(),\n",
    "    LLM,\n",
    "    prompt=QUERY_PROMPT\n",
    ")\n",
    "\n",
    "# RAG prompt\n",
    "template = \"\"\" Answer the question based ONLY on the following context:\n",
    "{context}\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = (\n",
    "    {'context': retriever, 'question': RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | LLM\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:07<00:00,  7.80s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:04<00:00,  4.66s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:05<00:00,  5.34s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:05<00:00,  5.04s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:05<00:00,  5.57s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:05<00:00,  5.26s/it]\n",
      "OllamaEmbeddings: 100%|██████████| 1/1 [00:11<00:00, 11.58s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'This appears to be a report or a document detailing the tasks and experiences of an intern (Data Analyst) during their internship at KPMG (Forage)-Remote from September 2023 to November 2023. The document outlines various projects, tasks, and responsibilities undertaken by the intern, including data analysis, web development, communication with stakeholders, and quality control.'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(input('Ask question here: '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ragging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
